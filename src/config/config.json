{
  "benchmark": {
    "name": "Cross-Model Persona Transfer Benchmark",
    "description": "Systematic evaluation of persona vector transfer across multiple models, traits, layers, and magnitudes",
    "version": "1.0.0"
  },
  "models": {
    "qwen2.5-7b-instruct": {
      "id": "qwen2.5-7b-instruct",
      "hf_model_id": "Qwen/Qwen2.5-7B-Instruct",
      "num_layers": 28,
      "hidden_size": 3584,
      "description": "Qwen 2.5 7B Instruct model"
    },
    "llama-3.1-8b-instruct": {
      "id": "llama-3.1-8b-instruct",
      "hf_model_id": "meta-llama/Llama-3.1-8B-Instruct",
      "num_layers": 32,
      "hidden_size": 4096,
      "description": "LLaMA 3.1 8B Instruct model"
    },
    "mistral-7b-instruct": {
      "id": "mistral-7b-instruct",
      "hf_model_id": "mistralai/Mistral-7B-Instruct-v0.3",
      "num_layers": 32,
      "hidden_size": 4096,
      "description": "Mistral 7B Instruct model"
    }
  },
  "traits": {
    "silly": {
      "id": "silly",
      "name": "Silly / Humorous",
      "description": "Playful, humorous, whimsical responses vs serious, professional, factual",
      "category": "style"
    },
    "honest": {
      "id": "honest",
      "name": "Honest",
      "description": "Truthful, accurate, transparent vs misleading, deceptive",
      "category": "ethics"
    },
    "helpful": {
      "id": "helpful",
      "name": "Helpful",
      "description": "Useful, actionable, well-explained vs unhelpful, vague, dismissive",
      "category": "behavior"
    },
    "rude": {
      "id": "rude",
      "name": "Rude",
      "description": "Impolite, sharp, confrontational vs polite, respectful, courteous",
      "category": "behavior"
    },
    "concise": {
      "id": "concise",
      "name": "Concise",
      "description": "Brief, to-the-point, minimal responses vs verbose, detailed, elaborate",
      "category": "style"
    },
    "verbose": {
      "id": "verbose",
      "name": "Verbose",
      "description": "Detailed, elaborate, expansive responses vs concise, brief, terse",
      "category": "style"
    }
  },
  "layers": {
    "early": {
      "name": "Early Layers",
      "description": "First 1/3 of transformer layers (low-level features)",
      "range_ratio": [0.0, 0.33]
    },
    "mid": {
      "name": "Middle Layers",
      "description": "Middle 1/3 of transformer layers (mid-level abstractions)",
      "range_ratio": [0.33, 0.67]
    },
    "late": {
      "name": "Late Layers",
      "description": "Last 1/3 of transformer layers (high-level reasoning)",
      "range_ratio": [0.67, 1.0]
    },
    "all": {
      "name": "All Layers",
      "description": "All transformer layers uniformly",
      "range_ratio": [0.0, 1.0]
    }
  },
  "magnitudes": {
    "alpha_grid": [0.0, 0.5, 1.0, 2.0, 4.0],
    "description": "Steering coefficient (alpha) values for controlling persona strength"
  },
  "evaluation": {
    "metrics": {
      "trait_strength": {
        "name": "Trait Strength",
        "description": "LLM-based judge evaluation of how strongly the persona trait is expressed (0-10)",
        "type": "llm_judge",
        "scale": "0-10"
      },
      "coherence": {
        "name": "Coherence / Fluency",
        "description": "Perplexity-based coherence metric under target model",
        "type": "perplexity",
        "scale": "lower is better"
      }
    },
    "num_eval_questions_per_trait": 10,
    "num_responses_per_question": 1,
    "llm_judge_model": "gpt-5-mini-2025-08-07",
    "judge_prompt_template": "Evaluate how strongly the following persona trait is expressed in this response.\n\nTrait: {trait}\nResponse: {response}\n\nRate on a scale of 0-10, where 0 means the trait is not expressed at all, and 10 means it is very strongly expressed. Respond with ONLY the number."
  },
  "experiment_settings": {
    "num_runs": 1,
    "seed": 42,
    "output_dir": "experiments/cross_model_benchmark/",
    "save_responses": true,
    "save_vectors": true
  }
}
